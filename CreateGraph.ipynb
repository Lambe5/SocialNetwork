{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEGENDA 'Conservation Status'\n",
    "Least Concern (LC): Indica che una specie non è attualmente a rischio di estinzione. Queste specie sono considerate relativamente sicure in natura.\n",
    "\n",
    "Vulnerable (VU): Indica che una specie è a rischio di estinzione in natura, ma non è ancora considerata in pericolo critico. Le specie vulnerabili potrebbero avere una popolazione ridotta o affrontare minacce significative nell'ambiente circostante.\n",
    "\n",
    "Endangered (EN): Indica che una specie è a rischio di estinzione imminente in natura. Queste specie hanno una popolazione molto bassa e/o affrontano minacce gravi che mettono a rischio la loro sopravvivenza.\n",
    "\n",
    "Not Evaluated (NE): Indica che lo stato di conservazione di una specie non è stato ancora valutato o non è disponibile alcuna informazione sulla sua popolazione o sulle minacce che affronta.\n",
    "\n",
    "Near Threatened (NT): Indica che una specie non è ancora classificata come vulnerabile, ma potrebbe diventarlo in futuro se le minacce che affronta non vengono affrontate o se la popolazione continua a diminuire.\n",
    "\n",
    "Critically Endangered (CR): Indica che una specie è in grave pericolo di estinzione in natura. Le specie classificate come criticamente in pericolo hanno una popolazione estremamente bassa e/o affrontano minacce estreme che mettono a rischio la loro sopravvivenza nel breve termine.\n",
    "\n",
    "Varies: Indica che lo stato di conservazione di una specie varia, a seconda delle diverse popolazioni o sotto-specie che possono essere classificate in modi diversi.\n",
    "\n",
    "Data Deficient (DD): Indica che non ci sono dati sufficienti per valutare lo stato di conservazione di una specie. Questo può essere dovuto alla mancanza di informazioni sulla popolazione, sulle minacce o sulla distribuzione della specie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import networkx as nx\n",
    "import inflect\n",
    "from networkx.algorithms import cluster, community\n",
    "import itertools\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv('datasetAnimali/Animal Dataset.csv'))\n",
    "df['index'] = df.index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueValues(column_name):\n",
    "    return df[column_name].unique()\n",
    "\n",
    "def contaValoriUnici(dataset,colonna):\n",
    "    for i in dataset[colonna].unique():\n",
    "        print(\"Valore \",i,\"counts: \",(dataset[colonna] ==i).sum())\n",
    "\n",
    "def addPredators(nome_preda, arr_predators):\n",
    "    for nome_predatore in arr_predators:\n",
    "        df.loc[df['Animal'] == nome_preda, 'Predators'] = df.loc[df['Animal'] == nome_preda, 'Predators'] + ', ' + nome_predatore\n",
    "        \n",
    "def replacePreators(nome_preda, arr_predators):\n",
    "    df.loc[df['Animal'] == nome_preda, 'Predators'] = arr_predators[0]\n",
    "    for nome_predatore in arr_predators:\n",
    "        if nome_predatore != arr_predators[0]:\n",
    "            df.loc[df['Animal'] == nome_preda, 'Predators'] = df.loc[df['Animal'] == nome_preda, 'Predators'] + ', ' + nome_predatore\n",
    "\n",
    "def plural_to_singular(plural_words):\n",
    "    p = inflect.engine()\n",
    "    singular_words = []\n",
    "    for word in plural_words:\n",
    "        singular_word = p.singular_noun(word)\n",
    "        if singular_word:\n",
    "            singular_words.append(singular_word)\n",
    "        else:\n",
    "            singular_words.append(word)\n",
    "    return singular_words\n",
    "\n",
    "def plural_to_singular_word(word):\n",
    "    p = inflect.engine()\n",
    "    singular = p.singular_noun(word)\n",
    "    if singular:\n",
    "        return singular\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "#stampa archi entranti e uscenti di un certo animale\n",
    "def visualize_node_edges(G, node_name):\n",
    "    if node_name in G.nodes():\n",
    "        successors = list(G.successors(node_name))\n",
    "        predecessors = list(G.predecessors(node_name))\n",
    "        \n",
    "        print(f\"Gli archi uscenti dal nodo {node_name} sono:\")\n",
    "        for successor in successors:\n",
    "            print(f\"{node_name} -> {successor}\")\n",
    "        \n",
    "        print(f\"\\nGli archi entranti nel nodo {node_name} sono:\")\n",
    "        for predecessor in predecessors:\n",
    "            print(f\"{predecessor} -> {node_name}\")\n",
    "    else:\n",
    "        print(f\"Il nodo {node_name} non esiste nel grafo.\")\n",
    "\n",
    "def transform_weight(weight_str):\n",
    "    if \"Up to\" in weight_str:\n",
    "        return float(re.findall(r'\\d*\\.?\\d+', weight_str)[0])\n",
    "    else:\n",
    "        if weight_str == 'Varies':\n",
    "            return -1\n",
    "        min_weight, max_weight = map(float, re.findall(r'\\d*\\.?\\d+', weight_str))\n",
    "        return (min_weight + max_weight) / 2\n",
    "    \n",
    "def label_weight(weight):\n",
    "    if weight == -1:\n",
    "        return 'Not Applicable'\n",
    "    elif weight < 30:\n",
    "        return 'Small'\n",
    "    elif 30 <= weight <= 60:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Heavy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stampa i nodi che contengono una certa parola\n",
    "def find_nodes_containing_keyword(G, keyword):\n",
    "    matching_nodes = []\n",
    "    for node in G.nodes():\n",
    "        if keyword.lower() in node.lower():\n",
    "            matching_nodes.append(node)\n",
    "    return matching_nodes\n",
    "\n",
    "# keyword = \"orangutan\"\n",
    "# matching_nodes = find_nodes_containing_keyword(G, keyword)\n",
    "# if matching_nodes:\n",
    "#     print(f\"I nodi che contengono la parola '{keyword}' nel loro nome sono:\")\n",
    "#     for node in matching_nodes:\n",
    "#         print(node)\n",
    "# else:\n",
    "#     print(f\"Nessun nodo trovato contenente la parola '{keyword}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droppare animali estinti, i predatori Not Applicable e quelli che non hanno una area geografica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino gli animali duplicati nella colonna Animal\n",
    "indici_righe_da_eliminare = [82, 85, 106, 110, 124, 131]\n",
    "df.drop(indici_righe_da_eliminare, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addPredators('African Elephant', ['Crocodile'])\n",
    "replacePreators('Alpine Ibex', ['Mountain Tigers','Wolves', 'Lynxes', 'Bears', 'Foxes'])\n",
    "replacePreators('Amazon Rainforest Frog', ['leimadophis epinephelus'])\n",
    "replacePreators('Arabian Oryx', ['Striped Hyenas', 'Arabian Wolves', 'Lions'])\n",
    "replacePreators('Arctic Fox', ['Polar Bears', 'Wolves', 'Golden Eagles', 'Grizzly Bears', 'Bald Eagles'])\n",
    "replacePreators('Asian Elephant', ['Tigres'])\n",
    "replacePreators('Atlantic Puffin', ['Great Skua', 'Great Black-backed Gull', 'Foxes'])\n",
    "addPredators('Aye-Aye', ['Fossas'])\n",
    "addPredators('Baird\\'s Tapir', ['Pumas'])\n",
    "replacePreators('Bald Eagle', ['Owls', 'Raccoons', 'Wolverines', 'Crows', 'Hawks'])\n",
    "addPredators('Banded Palm Civet', ['Owls', 'Snakes'])\n",
    "addPredators('Barbary Macaque', ['Domestic Dogs'])\n",
    "addPredators('Bearded Dragon', ['Foxes'])\n",
    "replacePreators('Blue Jay', ['Hawks', 'Owls', 'Falcons', 'Snakes'])\n",
    "addPredators('Blue-Footed Booby\t', ['Galapagos Hawk'])\n",
    "replacePreators('Bornean Orangutan', ['Leopards', 'Bearded Pigs', 'Crocodiles', 'Pythons', 'Black Eagles'])\n",
    "replacePreators('Bottlenose Dolphin', ['Tiger Sharks', 'Dusky Sharks', 'Bull Sharks', 'Great White Sharks'])\n",
    "replacePreators('Brown Bear', ['Wolves', 'Cougars'])\n",
    "replacePreators('Burmese Python', ['Asian Tigres', 'Leopards'])\n",
    "addPredators('Capybara', ['Caimans'])\n",
    "addPredators('Cheetah', ['Leopards'])\n",
    "replacePreators('Chinese Giant Salamander', ['Otters', 'Foxes', 'Weasels', 'Badgers'])\n",
    "replacePreators('Common Snapping Turtle', ['Foxes', 'Coyotes', 'Skunks', 'Minks', 'Fishers', 'Raccoons', 'Crows', 'Herons', 'Hawks', 'Owls', 'Bullfrogs', 'Fish', 'Snakes'])\n",
    "replacePreators('Dhole', ['Not Applicable'])\n",
    "replacePreators('Dingo', ['Crocodiles', 'Canid Species'])\n",
    "addPredators('Dugong', ['Saltwater Crocodiles'])\n",
    "addPredators('Eastern Gorilla', ['Crocodiles'])\n",
    "addPredators('Echidna', ['Feral Cats', 'Foxes', 'Goannas'])\n",
    "addPredators('Emperor Penguin', ['Sea Lions', 'Orcas'])\n",
    "addPredators('Emperor Tamarin', ['Wild Cats', 'Dogs', 'Snakes', 'Birds of Prey'])\n",
    "addPredators('Fennec Fox', ['Large Mammals'])\n",
    "replacePreators('Flying Fox', ['Eagles', 'Owls', 'Pythons'])\n",
    "addPredators('Galápagos Penguin', ['Sea Lions', 'Snakes', 'Owls', 'Hawks'])\n",
    "replacePreators('Galápagos Tortoise', ['Galápagos hawk'])\n",
    "addPredators('Gaur', ['Dhole', 'Saltwater Crocodiles'])\n",
    "addPredators('Gerenuk', ['African Wild Dogs', 'Cheetahs', 'Hyenas'])\n",
    "addPredators('Giant Panda', ['Yellow-Throated Martens', 'Eagles', 'Feral Dogs', 'Asian Black Bear'])\n",
    "addPredators('Gila Monster', ['Hawks', 'Owls', 'Snakes'])\n",
    "addPredators('Golden Lion Tamarin', ['Wild Cats'])\n",
    "addPredators('Green Anaconda', ['Crab-eating Foxes', 'Tegu Lizards', 'Crested Caracaras'])\n",
    "addPredators('Grevy\\'s Zebra', ['Leopards', 'Hunting Dogs', 'Cheetah'])\n",
    "addPredators('Harp Seal', ['Large Sharks'])\n",
    "replacePreators('Hummingbird', ['Owls', 'Grackles', 'Blue Jays', 'Herons', 'Tanagers', 'Loggerhead Shrikes', 'Gulls'])\n",
    "replacePreators('Japanese Macaque', ['Mountain Hawk Eagles', 'Feral Dogs', 'Raccoon Dogs'])\n",
    "replacePreators('Kangaroo Rat', ['Swift Foxes', 'Badgers', 'Bobcats',  'Coyotes', 'Snakes', 'Rattlesnakes', 'Raptors', 'Owls'])\n",
    "replacePreators('King Cobra', ['Birds', 'Mongooses'])\n",
    "addPredators('Lemur', ['Boas'])\n",
    "addPredators('Lion-tailed Macaque', ['Snakes', 'Raptors'])\n",
    "addPredators('Lyrebird', ['Quolls', 'Dogs', 'Feral Cats', 'Foxes'])\n",
    "addPredators('Mandrill', ['African Rock Pythons', 'Crowned Eagles'])\n",
    "replacePreators('Markhor', ['Eurasian Lynxs', 'Snow Leopards','Himalayan Wolfes', 'Brown Beas'])\n",
    "addPredators('Meerkat', ['Snakes'])\n",
    "replacePreators('Okapi', ['Leopards', 'Servals', 'Golden Cats'])\n",
    "addPredators('Orangutan', ['Large Pythons'])\n",
    "addPredators('Pangolin', ['Leopards', 'Hyenas', 'Pythons'])\n",
    "addPredators('Patagonian Mara', ['Felids', 'Grisons'])\n",
    "replacePreators('Pink Fairy Armadillo', ['Foxes', 'Birds of Prey', 'Birds', 'Canids'])\n",
    "replacePreators('Platypus', ['Snakes', 'Water Rats', 'Goannas', 'Foxes', 'Cats', 'Dogs'])\n",
    "replacePreators('Praying Mantis', ['Frogs', 'Lizards', 'Spiders', 'Hornets', 'Ants', 'Birds', 'Bats'])\n",
    "addPredators('Proboscis Monkey', ['Crocodiles', 'Pythons'])\n",
    "replacePreators('Pronghorn', ['Wolves', 'Foxes', 'Coyotes', 'Bobcats', 'Golden Eagles'])\n",
    "replacePreators('Rottweiler', ['Not Applicable'])\n",
    "addPredators('Serval', ['Wild Dogs'])\n",
    "replacePreators('Shoebill', ['Crocodiles'])\n",
    "replacePreators('Siberian Husky', ['Not Applicable'])\n",
    "addPredators('Sloth', ['Ocelots'])\n",
    "addPredators('Slow Loris', ['Orangutans', 'Hawk Eagles'])\n",
    "replacePreators('Snow Leopard', ['Humans'])\n",
    "replacePreators('Spider Monkey', ['Jaguars', 'Eagles', 'Snakes'])\n",
    "replacePreators('Spotted Hyena', ['Lions'])\n",
    "replacePreators('Star-Nosed Mole', ['Raptors', 'Screech', 'Great Horned', 'Long-Eared', 'Barred', 'Barn Owls', 'Red-Tailed Hawks'])\n",
    "addPredators('Sumatran Orangutan', ['Clouded Leopards', 'Large Pythons', 'Crocodiles'])\n",
    "addPredators('Tarsier', ['Monitor Lizards', 'Raptors'])\n",
    "replacePreators('Termite', ['Echidnas', 'Foxes', 'Galagos', 'Numbats', 'Mongooses', 'Mice', 'Pangolins', 'Genets', 'Civits', 'Bats', 'Echidnas', 'Moles', 'Shrews', 'Bibbies'])\n",
    "addPredators('Three-Toed Sloth', ['Ocelots', 'Jaguars'])\n",
    "replacePreators('Toco Toucan', ['Forest Eagles', 'Hawks', 'Owls', 'Boas', 'Jaguars', 'Margays'])\n",
    "addPredators('Tuatara', ['Birds of Pray'])\n",
    "replacePreators('Tufted Puffin', ['Bald Eagles', 'Peregrine Falcons', 'Snowy Owls', 'Eagle Owls', 'Sharks', 'Artic foxes', 'Red Foxes'])\n",
    "addPredators('Uakari', ['Birds of Pray'])\n",
    "addPredators('Vampire Bat', ['Eagles'])\n",
    "addPredators('Vaquita', ['Orcas'])\n",
    "replacePreators('Vulture', ['Hawks', 'Snakes', 'Wild Cats'])\n",
    "addPredators('Warthog', ['Spotted Hyenas', 'Cheetahs', 'African Wild Dogs'])\n",
    "addPredators('Water Buffalo', ['Lions'])\n",
    "replacePreators('Wild Boar', ['Wolves'])\n",
    "addPredators('Wildebeest', ['Hyenas', 'Cheetahs', 'Wild Dogs'])\n",
    "addPredators('Wolverine', ['Mountain Lions'])\n",
    "replacePreators('Wombat', ['Foxes', 'Dingoes', 'Wild Dogs', 'Eagles', 'Tasmanian Devils'])\n",
    "addPredators('Woodpecker', ['Feral Cats', 'Foxes', 'Hawks', 'Coyotes'])\n",
    "addPredators('Yellow-Eyed Penguin', ['Cats', 'Stoats', 'Dogs', 'Ferrets', 'Barracoota', 'Sharks', 'Sea Lions'])\n",
    "addPredators('Zebra', ['Wild dogs', 'Cheetahs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Predators.unique()\n",
    "df = df.rename(columns={'Predators': 'AllPredators'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droppo animali estinti\n",
    "df = df.loc[(df['Conservation Status'] != 'Extinct (around 4,000 years ago)') &\n",
    "             (df['Conservation Status'] != 'Extinct (around 58 million years ago)') &\n",
    "               (df['Conservation Status'] != 'Extinct')]\n",
    "\n",
    "# Deroppo gli animali che non hanno predatori e che non hanno uno stato di conservazione definito\n",
    "df = df.loc[(df['AllPredators'] != 'Not Applicable') & (df['Conservation Status'] != 'Not Applicable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estraiamo gli animali e i predatori in un unico elenco\n",
    "animals = df['Animal'].tolist()\n",
    "predators = df['AllPredators'].str.split(', ').explode().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animali_duplicati = df[df.duplicated(subset=['Animal'], keep=False)]\n",
    "animali_duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_predators = plural_to_singular(predators)\n",
    "\n",
    "animali_comuni = set(sing_predators).intersection(set(animals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# Aggiungere nodi al grafo con lo stato di conservazione, se presente\n",
    "for animal in animals:\n",
    "    status = df[df['Animal'] == animal]['Conservation Status'].iloc[0]\n",
    "    height = df[df['Animal'] == animal]['Height (cm)'].iloc[0]\n",
    "    weight = df[df['Animal'] == animal]['Weight (kg)'].iloc[0]\n",
    "    lifespan = df[df['Animal'] == animal]['Lifespan (years)'].iloc[0]\n",
    "    habitat = df[df['Animal'] == animal]['Habitat'].iloc[0]\n",
    "    family = df[df['Animal'] == animal]['Family'].iloc[0]\n",
    "    gestation_period = df[df['Animal'] == animal]['Gestation Period (days)'].iloc[0]\n",
    "    offspring_per_birth = df[df['Animal'] == animal]['Offspring per Birth'].iloc[0]\n",
    "    countries = df[df['Animal'] == animal]['Countries Found'].iloc[0]\n",
    "    pray = 'Yes'\n",
    "    if animal in animali_comuni:\n",
    "        pray = 'Not Only'\n",
    "    G.add_node(animal, conservation_status = status, pray = pray, height = height, weight = weight, lifespan = lifespan, habitat = habitat,\n",
    "               family = family, gestation_period = gestation_period, offspring_per_birth = offspring_per_birth, countries = countries)\n",
    "\n",
    "# Aggiungere nodi predatori al grafo solo se non sono presenti in animali_comuni\n",
    "for predator in sing_predators:\n",
    "    if predator not in animali_comuni:\n",
    "        G.add_node(predator, conservation_status = 'Not Have', pray = 'No')\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    animal = row['Animal']\n",
    "\n",
    "    for predator in row['AllPredators'].split(', '):\n",
    "        sing_predator = plural_to_singular_word(predator)\n",
    "        G.add_edge(sing_predator, animal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight (kg)'] = df['Weight (kg)'].str.replace(',', '.')\n",
    "df['Weight (kg)'] = df['Weight (kg)'].apply(transform_weight)\n",
    "\n",
    "#Adesso voglio raggruppare gli animali in leggeri, medi, grandi\n",
    "df['weight_labeled'] = df['Weight (kg)'].apply(label_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALISI STRUTTURA DELLA RETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betweenness centrality: Misura il numero di volte che un nodo si trova sul percorso più breve tra tutte le coppie di nodi nella rete. I nodi con betweenness elevato possono essere considerati \"ponti\" importanti tra le parti della rete --> utile per trovare gli animali che sono sia prede che predatori più rilevanti nel nostro dataset e che qundi potrebbero essere complici di un eventuale danno a catena indiretto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betweenness Centrality --> più il valore è alto più il nodo \n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "print(\"Betweenness Centrality:\", betweenness_centrality)\n",
    "max_bc_node = max(betweenness_centrality, key=betweenness_centrality.get)\n",
    "max_bc_value = betweenness_centrality[max_bc_node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trova i 10 nodi con i valori più alti di Betweenness Centrality\n",
    "top_10_bc_nodes = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)[:10]\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"I 10 nodi con i valori più alti di Betweenness Centrality:\")\n",
    "for node in top_10_bc_nodes:\n",
    "    print(node, \":\", betweenness_centrality[node])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il coefficiente di clustering di un grafo misura il grado in cui i nodi nel grafo tendono a formare cluster o raggruppamenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo del clustering coefficient\n",
    "clustering_coefficient = nx.average_clustering(G)\n",
    "print(\"Clustering Coefficient:\", clustering_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando esegui il rilevamento delle comunità su questo grafo, l'algoritmo cercherà di identificare gruppi di animali che sono più fortemente connessi tra loro rispetto alle connessioni con il resto del grafo --> utile per ottenre dei sotto-gruppi fortemente relazionati tra di loro, il che potrebbe anche implicare animali che appartengono allo stesso habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rilevamento delle comunità utilizzando l'approccio della modularity maximization\n",
    "communities = community.greedy_modularity_communities(G)\n",
    "\n",
    "# Creazione di un dizionario per mappare ogni specie alla sua comunità\n",
    "community_mapping = {}\n",
    "for idx, com in enumerate(communities):\n",
    "    for species in com:\n",
    "        community_mapping[species] = idx\n",
    "\n",
    "# Stampare le comunità identificate\n",
    "print(\"Community Detection:\")\n",
    "for species, community_id in community_mapping.items():\n",
    "    print(species, \":\", community_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifico le sottoreti presenti nella mia rete globale --> Utile per identificare animali chiave con pochi predaotori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificazione di sottoreti dense\n",
    "weakly_connected_components = list(nx.weakly_connected_components(G))\n",
    "\n",
    "# Creazione di sottografi per ciascuna componente connessa debole\n",
    "subgraphs = [G.subgraph(component) for component in weakly_connected_components]\n",
    "\n",
    "# Stampare le dimensioni delle sottoreti dense\n",
    "print(\"Dimensioni delle sottoreti dense:\")\n",
    "for i, subgraph in enumerate(subgraphs):\n",
    "    print(\"Sottorete\", i+1, \":\", subgraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubNetNodes(sub_net_nodes):\n",
    "    # Lista per memorizzare i nodi delle sottoreti dalla 2 alla 7\n",
    "    nodes_in_subnet = []\n",
    "    i = sub_net_nodes - 1\n",
    "    # Itera attraverso i sottografi dalla 2 alla 7\n",
    "    for subgraph in subgraphs[i:sub_net_nodes]:  # Partendo dall'indice 1 per selezionare il secondo sottografo\n",
    "        # Aggiungi i nodi del sottografo corrente alla lista\n",
    "        nodes_in_subnet.extend(subgraph.nodes())\n",
    "\n",
    "    # Rimuovi i duplicati, se presenti\n",
    "    nodes_in_subnet = list(set(nodes_in_subnet))\n",
    "\n",
    "    # Stampa i nodi delle sottoreti dalla 2 alla 7\n",
    "    print(\"Nodi nella sottorete:\", nodes_in_subnet)\n",
    "\n",
    "    #return nodes_in_subnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSubNetNodes(2)\n",
    "getSubNetNodes(3)\n",
    "getSubNetNodes(4)\n",
    "getSubNetNodes(5)\n",
    "getSubNetNodes(6)\n",
    "getSubNetNodes(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rilevamento delle comunità utilizzando l'approccio della modularity maximization\n",
    "communities = community.greedy_modularity_communities(G)\n",
    "\n",
    "# Calcolo della betweenness centrality\n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "\n",
    "# Creazione di un dizionario per mappare ogni specie alla sua comunità e alla sua betweenness centrality\n",
    "node_attributes = {}\n",
    "for idx, com in enumerate(communities):\n",
    "    for species in com:\n",
    "        node_attributes[species] = {'community': idx, 'betweenness_centrality': betweenness[species]}\n",
    "\n",
    "# Aggiunta dei valori delle comunità e della betweenness centrality come attributi ai nodi del grafo\n",
    "nx.set_node_attributes(G, node_attributes)\n",
    "\n",
    "# Stampare le informazioni identificate per ogni nodo\n",
    "print(\"Node Information:\")\n",
    "for node, data in G.nodes(data=True):\n",
    "    print(\"Node:\", node, \"Community:\", data['community'], \"Betweenness Centrality:\", data['betweenness_centrality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_by_community(nome_feature):\n",
    "    # Dizionario per mappare ogni comunità ai suoi stati di conservazione\n",
    "    community_conservation_status = {}\n",
    "\n",
    "    # Riempire il dizionario community_conservation_status con gli stati di conservazione di ogni comunità\n",
    "    for species, community_id in community_mapping.items():\n",
    "        conservation_status = df.loc[df['Animal'] == species, nome_feature].values\n",
    "        if len(conservation_status) > 0:\n",
    "            conservation_status = conservation_status[0]\n",
    "            if community_id not in community_conservation_status:\n",
    "                community_conservation_status[community_id] = set()\n",
    "            community_conservation_status[community_id].add(conservation_status)\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    # Calcoliamo la Jaccard Similarity tra tutte le coppie di comunità\n",
    "    for pair in itertools.combinations(community_conservation_status.keys(), 2):\n",
    "        conservation_status_set1 = community_conservation_status[pair[0]]\n",
    "        conservation_status_set2 = community_conservation_status[pair[1]]\n",
    "        \n",
    "        intersection = len(conservation_status_set1.intersection(conservation_status_set2))\n",
    "        union = len(conservation_status_set1.union(conservation_status_set2))\n",
    "        jaccard_similarity_score = intersection / union if union != 0 else 0\n",
    "        \n",
    "        similarities.append((pair, jaccard_similarity_score))\n",
    "\n",
    "    # Ordiniamo le coppie in base al grado di similarità\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard Similarity tra comunità in base allo stato di conservazione\n",
    "#posso applicare la jaccard similarity anche in base all'habitat, dieta, e peso degli animali per comunità\n",
    "\n",
    "similarities = jaccard_similarity_by_community('Conservation Status')\n",
    "\n",
    "# Stampa le prime 10 coppie con il grado di similarità maggiore\n",
    "for i in range(min(10, len(similarities))):\n",
    "    pair, similarity = similarities[i]\n",
    "    print(f\"Community {pair[0]} e Community {pair[1]} con similarità {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectance: rappresenta la percentuale di connessioni effettivamente presenti rispetto al numero massimo di connessioni possibili.\n",
    "\n",
    "Edge-to-Node-Ratio: fornisce una stima del numero medio di collegamenti (archi) per nodo nella rete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connectance & Edge-to-Node-Ratio\n",
    "\n",
    "# Calcolo del numero totale di nodi e di archi nel grafo\n",
    "total_nodes = G.number_of_nodes()\n",
    "total_edges = G.number_of_edges()\n",
    "\n",
    "print(\"Numero totale di nodi nel grafo:\", total_nodes)\n",
    "print(\"Numero totale di archi nel grafo:\", total_edges)\n",
    "\n",
    "# Calcolo della Connectance\n",
    "connectance = total_edges / (total_nodes ** 2)\n",
    "\n",
    "# Calcolo dell'Edge-to-Node-Ratio\n",
    "edge_to_node_ratio = total_edges / total_nodes\n",
    "\n",
    "print(\"Connectance:\", connectance)\n",
    "print(\"Edge-to-Node-Ratio:\", edge_to_node_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gexf(G, 'new_animals_cleared.gexf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closeness centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non si può fare perché i nodi non sono pesati e non è possibile sapere qual è la distanza tra i due nodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubs And Authorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs , auothorities = nx.hits(G)\n",
    "{k: v for k,v in sorted(hubs.items(), key= lambda item: item[1],reverse=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v for k,v in sorted(auothorities.items(), key= lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_centrality = nx.eigenvector_centrality(G, max_iter=1000, tol=1e-6)\n",
    "sorted(((v,f\"{c:0.6f}\") for v,c in ev_centrality.items()), key= lambda item:item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katz centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "katz_centrality = nx.katz_centrality(G,alpha=0.85)\n",
    "for n, c in sorted(katz_centrality.items(), key= lambda item:item[1], reverse=True):\n",
    "    print(f\"{n} {c:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
